# æˆæœ¬ä¼˜åŒ–å®æ–½æŒ‡å—ï¼šRedis ç¼“å­˜é›†æˆ

**æ–‡æ¡£ç¼–å·**: 007-CACHE-IMPL  
**åˆ›å»ºæ—¥æœŸ**: 2025-12-17  
**çŠ¶æ€**: å®æ–½ä¸­

---

## âœ… å·²å®Œæˆå·¥ä½œ

### 1. CacheService å®ç°

**æ–‡ä»¶**: `backend/app/services/cache_service.py`

**åŠŸèƒ½**:
- âœ… å¼‚æ­¥ Redis æ“ä½œ
- âœ… è‡ªåŠ¨ JSON åºåˆ—åŒ–/ååºåˆ—åŒ–
- âœ… TTL ç®¡ç†ï¼ˆä¸åŒç±»å‹ä¸åŒ TTLï¼‰
- âœ… ç¼“å­˜é”®ç”Ÿæˆï¼ˆMD5 å“ˆå¸Œï¼‰
- âœ… è¿æ¥ç®¡ç†
- âœ… ç»Ÿè®¡ä¿¡æ¯

**ä»£ç é‡**: ~250 è¡Œ

---

## ğŸ”¨ å¾…é›†æˆå·¥ä½œ

### 2. é›†æˆåˆ° ProductSelectionService

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/services/ai/product_selection.py`

**éœ€è¦ä¿®æ”¹çš„åœ°æ–¹**:

```python
# 1. æ·»åŠ å¯¼å…¥
from app.services.cache_service import CacheService

# 2. ä¿®æ”¹ __init__ æ–¹æ³•
class ProductSelectionService:
    def __init__(
        self,
        sorftime_client: SorftimeClient,
        deepseek_client: DeepSeekClient,
        cache_service: Optional[CacheService] = None  # æ–°å¢
    ):
        self.sorftime = sorftime_client
        self.ai = deepseek_client
        self.prompts = PromptTemplates()
        self.cache = cache_service  # æ–°å¢

# 3. ä¿®æ”¹ analyze_category æ–¹æ³•
async def analyze_category(
    self,
    category_id: str,
    domain: int = 1,
    use_cache: bool = True
) -> Dict[str, Any]:
    logger.info(f"Starting category analysis: category_id={category_id}, domain={domain}")
    
    # éªŒè¯å‚æ•°
    if not category_id:
        raise ValueError("category_id is required")
    
    # ===== æ–°å¢ï¼šæ£€æŸ¥ç¼“å­˜ =====
    if use_cache and self.cache:
        cache_key = self.cache.generate_key(
            "product_selection",
            category_id=category_id,
            domain=domain
        )
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            logger.info(f"Returning cached result for {category_id}")
            return cached_result
    # ===== ç¼“å­˜æ£€æŸ¥ç»“æŸ =====
    
    # 1. è·å–ç±»ç›®æ•°æ®
    logger.info("Fetching category data from Sorftime API")
    category_data = await self._fetch_category_data(category_id, domain)
    
    # 2-4. åŸæœ‰é€»è¾‘ï¼ˆæ„å»º Promptã€AI åˆ†æã€è§£æç»“æœï¼‰
    # ... ä¿æŒä¸å˜ ...
    
    # 5. æ„å»ºè¿”å›ç»“æœ
    result = {
        "category_id": category_id,
        "category_name": category_data.get("name", category_id),
        "domain": domain,
        "market_score": market_score,
        "analysis": analysis,
        "raw_data": category_data,
        "statistics": {
            "avg_price": category_data.get("avg_price"),
            "avg_rating": category_data.get("avg_rating"),
            "avg_reviews": category_data.get("avg_reviews"),
            "competition_level": category_data.get("competition_level", "ä¸­ç­‰")
        },
        "timestamp": datetime.utcnow().isoformat()
    }
    
    # ===== æ–°å¢ï¼šä¿å­˜åˆ°ç¼“å­˜ =====
    if use_cache and self.cache:
        ttl = self.cache.get_ttl_for_type("product_selection")  # 24 å°æ—¶
        await self.cache.set(cache_key, result, ttl=ttl)
        logger.info(f"Cached result for {category_id}, TTL: {ttl}s")
    # ===== ç¼“å­˜ä¿å­˜ç»“æŸ =====
    
    logger.info(f"Analysis completed. Market score: {market_score}/10")
    return result
```

---

### 3. é›†æˆåˆ° KeywordOptimizationService

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/services/ai/keyword_optimization.py`

**ç±»ä¼¼çš„ä¿®æ”¹**:
1. æ·»åŠ  `cache_service` å‚æ•°
2. åœ¨ `optimize_listing` æ–¹æ³•å¼€å¤´æ£€æŸ¥ç¼“å­˜
3. åœ¨æ–¹æ³•ç»“å°¾ä¿å­˜åˆ°ç¼“å­˜

---

### 4. æ›´æ–° API ç«¯ç‚¹ä¾èµ–æ³¨å…¥

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/api/v1/endpoints/ai.py`

```python
from app.services.cache_service import get_cache_service, CacheService

# æ·»åŠ ç¼“å­˜æœåŠ¡ä¾èµ–
def get_cache() -> CacheService:
    """è·å–ç¼“å­˜æœåŠ¡"""
    return get_cache_service()

# æ›´æ–°æœåŠ¡ä¾èµ–
def get_product_selection_service(
    sorftime: SorftimeClient = Depends(get_sorftime_client),
    deepseek: DeepSeekClient = Depends(get_deepseek_client),
    cache: CacheService = Depends(get_cache)  # æ–°å¢
) -> ProductSelectionService:
    """è·å–äº§å“é€‰å“æœåŠ¡"""
    return ProductSelectionService(sorftime, deepseek, cache)  # ä¼ å…¥ cache

def get_keyword_optimization_service(
    sorftime: SorftimeClient = Depends(get_sorftime_client),
    deepseek: DeepSeekClient = Depends(get_deepseek_client),
    cache: CacheService = Depends(get_cache)  # æ–°å¢
) -> KeywordOptimizationService:
    """è·å–å…³é”®è¯ä¼˜åŒ–æœåŠ¡"""
    return KeywordOptimizationService(sorftime, deepseek, cache)  # ä¼ å…¥ cache
```

---

### 5. ç¯å¢ƒé…ç½®

**æ–‡ä»¶**: `.env`

```bash
# Redis é…ç½®
REDIS_URL=redis://localhost:6379/0

# æˆ–è€…ä½¿ç”¨ Docker
REDIS_URL=redis://redis:6379/0
```

**æ–‡ä»¶**: `docker-compose.yml`

```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

volumes:
  redis_data:
```

---

### 6. ä¾èµ–å®‰è£…

**æ–‡ä»¶**: `backend/requirements.txt`

```
redis[hiredis]>=5.0.0
```

**å®‰è£…å‘½ä»¤**:

```bash
cd backend
pip install redis[hiredis]
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### ç¼“å­˜å‘½ä¸­ç‡

| åœºæ™¯ | é¢„æœŸå‘½ä¸­ç‡ | è¯´æ˜ |
|------|-----------|------|
| çƒ­é—¨ç±»ç›® | 80-90% | ç»å¸¸è¢«æŸ¥è¯¢ |
| ä¸€èˆ¬ç±»ç›® | 60-70% | å¶å°”è¢«æŸ¥è¯¢ |
| å†·é—¨ç±»ç›® | 20-30% | å¾ˆå°‘è¢«æŸ¥è¯¢ |
| **å¹³å‡** | **70%** | æ€»ä½“é¢„æœŸ |

### æˆæœ¬èŠ‚çœ

**å‡è®¾**:
- æ¯å¤© 100 æ¬¡æŸ¥è¯¢
- ç¼“å­˜å‘½ä¸­ç‡ 70%
- å•æ¬¡ API æˆæœ¬ $0.023

**è®¡ç®—**:
- æ— ç¼“å­˜æˆæœ¬ï¼š100 Ã— $0.023 = $2.30/å¤©
- æœ‰ç¼“å­˜æˆæœ¬ï¼š30 Ã— $0.023 = $0.69/å¤©
- **èŠ‚çœ**ï¼š$1.61/å¤© = **$48.30/æœˆ**

### å“åº”é€Ÿåº¦

| åœºæ™¯ | æ— ç¼“å­˜ | æœ‰ç¼“å­˜ | æå‡ |
|------|--------|--------|------|
| é€‰å“åˆ†æ | 20-30s | 0.1-0.5s | **40-300 å€** |
| å…³é”®è¯ä¼˜åŒ– | 15-20s | 0.1-0.5s | **30-200 å€** |

---

## ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

### 1. å•å…ƒæµ‹è¯•

```python
# tests/services/test_cache_service.py

import pytest
from app.services.cache_service import CacheService

@pytest.mark.asyncio
async def test_cache_set_and_get():
    cache = CacheService("redis://localhost:6379")
    await cache.connect()
    
    # è®¾ç½®ç¼“å­˜
    key = "test_key"
    value = {"data": "test"}
    await cache.set(key, value, ttl=60)
    
    # è·å–ç¼“å­˜
    result = await cache.get(key)
    assert result == value
    
    # æ¸…ç†
    await cache.delete(key)
    await cache.disconnect()

@pytest.mark.asyncio
async def test_cache_miss():
    cache = CacheService("redis://localhost:6379")
    await cache.connect()
    
    result = await cache.get("nonexistent_key")
    assert result is None
    
    await cache.disconnect()
```

### 2. é›†æˆæµ‹è¯•

```python
# tests/api/test_ai_with_cache.py

@pytest.mark.asyncio
async def test_product_selection_with_cache(client):
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆæ— ç¼“å­˜ï¼‰
    response1 = client.post("/api/v1/ai/product-selection", json={
        "category_id": "172282",
        "domain": 1,
        "use_cache": True
    })
    assert response1.status_code == 200
    time1 = response1.elapsed.total_seconds()
    
    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆæœ‰ç¼“å­˜ï¼‰
    response2 = client.post("/api/v1/ai/product-selection", json={
        "category_id": "172282",
        "domain": 1,
        "use_cache": True
    })
    assert response2.status_code == 200
    time2 = response2.elapsed.total_seconds()
    
    # éªŒè¯ç¼“å­˜æ•ˆæœ
    assert time2 < time1 / 10  # ç¼“å­˜åº”è¯¥å¿« 10 å€ä»¥ä¸Š
    assert response1.json()["market_score"] == response2.json()["market_score"]
```

---

## ğŸ“ å®æ–½æ­¥éª¤

### Step 1: å¯åŠ¨ Redisï¼ˆ5 åˆ†é’Ÿï¼‰

```bash
# ä½¿ç”¨ Docker
docker run -d --name redis -p 6379:6379 redis:7-alpine

# æˆ–æ·»åŠ åˆ° docker-compose.yml
docker-compose up -d redis
```

### Step 2: å®‰è£…ä¾èµ–ï¼ˆ2 åˆ†é’Ÿï¼‰

```bash
cd backend
pip install redis[hiredis]
```

### Step 3: ä¿®æ”¹æœåŠ¡ä»£ç ï¼ˆ30 åˆ†é’Ÿï¼‰

1. ä¿®æ”¹ `ProductSelectionService.__init__`
2. ä¿®æ”¹ `ProductSelectionService.analyze_category`
3. ä¿®æ”¹ `KeywordOptimizationService.__init__`
4. ä¿®æ”¹ `KeywordOptimizationService.optimize_listing`

### Step 4: æ›´æ–° API ç«¯ç‚¹ï¼ˆ10 åˆ†é’Ÿï¼‰

1. æ·»åŠ  `get_cache` ä¾èµ–
2. æ›´æ–°æœåŠ¡ä¾èµ–æ³¨å…¥

### Step 5: æµ‹è¯•ï¼ˆ15 åˆ†é’Ÿï¼‰

1. å¯åŠ¨æœåŠ¡
2. æµ‹è¯•é€‰å“ APIï¼ˆç¬¬ä¸€æ¬¡æ…¢ï¼Œç¬¬äºŒæ¬¡å¿«ï¼‰
3. æµ‹è¯•å…³é”®è¯ API
4. æ£€æŸ¥ Redis æ•°æ®

### Step 6: ç›‘æ§ï¼ˆæŒç»­ï¼‰

1. è§‚å¯Ÿç¼“å­˜å‘½ä¸­ç‡
2. ç»Ÿè®¡æˆæœ¬èŠ‚çœ
3. ä¼˜åŒ– TTL é…ç½®

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

- âœ… Redis æœåŠ¡æ­£å¸¸è¿è¡Œ
- âœ… ç¼“å­˜å‘½ä¸­ç‡ > 70%
- âœ… å“åº”é€Ÿåº¦æå‡ > 10 å€
- âœ… æˆæœ¬èŠ‚çœ > 60%
- âœ… æ— åŠŸèƒ½å›å½’é—®é¢˜

---

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **Redis å¯ç”¨æ€§**
   - å¦‚æœ Redis ä¸å¯ç”¨ï¼ŒæœåŠ¡åº”é™çº§åˆ°æ— ç¼“å­˜æ¨¡å¼
   - å·²åœ¨ CacheService ä¸­å®ç°å®¹é”™

2. **ç¼“å­˜å¤±æ•ˆ**
   - å¸‚åœºæ•°æ®å˜åŒ–æ—¶éœ€è¦æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜
   - å¯ä»¥æ·»åŠ ç®¡ç†æ¥å£

3. **å†…å­˜ç®¡ç†**
   - ç›‘æ§ Redis å†…å­˜ä½¿ç”¨
   - è®¾ç½®åˆç†çš„ maxmemory ç­–ç•¥

4. **æ•°æ®ä¸€è‡´æ€§**
   - ç¼“å­˜çš„æ•°æ®å¯èƒ½è¿‡æ—¶
   - é€šè¿‡ TTL æ§åˆ¶æ–°é²œåº¦

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Redis å®˜æ–¹æ–‡æ¡£](https://redis.io/docs/)
- [redis-py æ–‡æ¡£](https://redis-py.readthedocs.io/)
- [FastAPI ä¾èµ–æ³¨å…¥](https://fastapi.tiangolo.com/tutorial/dependencies/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2025-12-17  
**ä½œè€…**: AI Assistant  
**çŠ¶æ€**: CacheService å·²å®ç°ï¼Œå¾…é›†æˆåˆ°æœåŠ¡
